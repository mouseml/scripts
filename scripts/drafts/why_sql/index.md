# SQL В DATA SCIENCE ПРОЕКТАХ

> Обложка: SQL не нужен?

## Вступление

SQL — три буквы, которые есть в каждой вакансии Data Scientist-а, ML инженера или аналитика данных. При этом SQL обычно учат отдельно, а в портфолио обходят стороной. Из-за этого непонятно, как вложенные SQL запросы и оконные функции сочетаются с реальными проектами, где все данные уже подготовлены в виде `train.csv`.

Сегодня разберемся как SQL используется на каждом этапе Data Science проектов: от идеи до обучения модели. Посмотрим, как выполнять SQL запросы из Python и какие команды надо знать.

## Понять задачу

Типичный проект на работе начинается с размытой идеи. Задача Data Scientist-а — разобраться, какие данные ему доступны и в каком количестве. Это позволит перевести задачу на язык моделей и метрик или понять, что решить ее невозможно.

Разберем пример. Директор сети супермаркетов недоволен процессом планирования закупок. Сейчас им вручную занимаются региональные менеджеры. Они переносят закупки с прошлого года на следующий и изменяют план по ощущениям. Если магазин в центре Тулы продал 200 килограммов мандаринов в декабре 2024-го года, тульский региональный менеджер скорее всего закажет 200 или 220 килограммов к декабрю 2025-го.

Менеджеры часто ошибаются, а их ошибки дорого стоят. Лишний товар придется утилизировать, а если товара не хватит, покупатели уйдут за ним к конкуренту. Директор считает, что искусственный интеллект снизит ошибки при планировании. 

Другой информации о задаче у нас нет: нужно изучить данные и уточнить, что подразумевается под словом "планирование".

У нас есть только данные продаж: они ежедневно поступают от всех супермаркетов в общую базу данных. Отработаем все примеры на SQLite. В конце я разверну Postgres в облаке и покажу, как работать с любой другой базой данных. Если хотите повторять все действия вместе со мной, скачайте файл `data.db` из моей группы в Telegram. 

Для подключения к базе откройте терминал, перейдите в папку с файлом `data.db` и выполните команду:

```shell
sqlite3 data.db
```

Устанавливать дополнительно ничего не нужно — SQLite устанавливается вместе с любой версией Python. 

В терминале можно писать SQL запросы и встроенные команды SQLite. Посмотрим на доступные таблицы с помощью команды:

```sqlite
.tables
```
```text {.no-copy}
sales   stores
```

Видим две таблицы: `sales` с данными продаж и `stores` с данными магазинов.

Посмотрим на данные в каждой таблице. Выведем первые 5 строк таблицы `sales` с помощью запроса:

```sqlite
SELECT * FROM sales LIMIT 5;
```
```text {.no-copy}
┌─────────┬──────────┬────────────┬───────┬─────────────┬────────────┬──────────┬────────┐
│ sale_id │ store_id │    date    │ month │ day_of_week │ is_holiday │ is_promo │ amount │
├─────────┼──────────┼────────────┼───────┼─────────────┼────────────┼──────────┼────────┤
│ 0       │ 1        │ 2025-07-31 │ 7     │ 4           │ 0          │ 1        │ 315780 │
│ 1       │ 2        │ 2025-07-31 │ 7     │ 4           │ 0          │ 1        │ 363840 │
│ 2       │ 3        │ 2025-07-31 │ 7     │ 4           │ 0          │ 1        │ 498840 │
│ 3       │ 4        │ 2025-07-31 │ 7     │ 4           │ 0          │ 1        │ 839700 │
│ 4       │ 5        │ 2025-07-31 │ 7     │ 4           │ 0          │ 1        │ 289320 │
└─────────┴──────────┴────────────┴───────┴─────────────┴────────────┴──────────┴────────┘
```

Здесь `*` означает "все колонки".

В этой таблице содержится полная выручка каждого магазина за каждый день. Видим ID строки, ID магазина и дату продажи. Для удобства из даты выделены месяц и день недели: 1 означает понедельник, а 7 — воскресенье. Если в этот день был государственный праздник, флаг `is_holiday` равен 1. Флаг `is_promo` означает, что в этот день в магазине проводили акцию. Последняя колонка — выручка магазина в этот день в рублях.

Посмотрим на данные в таблице `stores`:

```sqlite
SELECT * FROM stores LIMIT 5;
```
```text {.no-copy}
┌──────────┬─────────────┬─────────────┬──────────────────────┐
│ store_id │ store_type  │ assortment  │ competition_distance │
├──────────┼─────────────┼─────────────┼──────────────────────┤
│ 1        │ супермаркет │ расширенный │ 1270                 │
│ 2        │ стандарт    │ расширенный │ 570                  │
│ 3        │ стандарт    │ расширенный │ 14130                │
│ 4        │ супермаркет │ базовый     │ 620                  │
│ 5        │ стандарт    │ расширенный │ 29910                │
└──────────┴─────────────┴─────────────┴──────────────────────┘
```

Здесь хранятся параметры магазина: тип магазина, тип ассортимента и расстояние до ближайшего магазина-конкурента в метрах.

Посчитаем количество записей в каждой таблице. Для этого используем функцию `COUNT`:

```sqlite
SELECT COUNT(*) FROM sales;
```
```text {.no-copy}
┌──────────┐
│ COUNT(*) │
├──────────┤
│ 808454   │
└──────────┘
```

Здесь `*` означает строку. Всего в таблице `sales` 808 тысяч строк.

Используем тот же запрос для таблицы `stores`:

```sqlite
SELECT COUNT(*) FROM stores;
```
```text {.no-copy}
┌──────────┐
│ COUNT(*) │
├──────────┤
│ 1112     │
└──────────┘
```

В таблице данные 1112 магазинов. 

Проверим диапазон времени в таблице `sales` — для этого используем функции `MIN` и `MAX`:

```sqlite
SELECT MIN(date), MAX(date) FROM sales;
```
```text {.no-copy}
┌────────────┬────────────┐
│ MIN(date)  │ MAX(date)  │
├────────────┼────────────┤
│ 2023-01-01 │ 2025-07-31 │
└────────────┴────────────┘
```

Данные продаж фиксировали с 1 января 2023 года до 31 июля 2025.

Выполним еще несколько запросов для базовой аналитики. Посчитаем минимальную, среднюю и максимальную дневную выручку по всем магазинам. Для этого используем функции `MIN`, `AVG` и `MAX`:

```sqlite
SELECT MIN(amount), AVG(amount), MAX(amount) FROM sales;
```
```text {.no-copy}
┌─────────────┬──────────────────┬─────────────┐
│ MIN(amount) │   AVG(amount)    │ MAX(amount) │
├─────────────┼──────────────────┼─────────────┤
│ 153420      │ 409014.884755348 │ 930480      │
└─────────────┴──────────────────┴─────────────┘
```

Магазины продают товаров 150-930 тысяч в день, 410 тысяч в среднем.

Посмотрим на среднюю выручку по дням недели. Выбираем колонку `day_of_week` и среднюю выручку. Используем предложение `GROUP BY` с колонкой `day_of_week` для группировки по дням недели:

```sqlite
SELECT day_of_week, AVG(amount) FROM sales GROUP BY day_of_week;
```
```text {.no-copy}
┌─────────────┬──────────────────┐
│ day_of_week │   AVG(amount)    │
├─────────────┼──────────────────┤
│ 1           │ 414162.389284508 │
│ 2           │ 396384.768643111 │
│ 3           │ 398410.75425161  │
│ 4           │ 415123.541302665 │
│ 5           │ 362229.093652136 │
│ 6           │ 468445.066562255 │
│ 7           │ 467223.357873807 │
└─────────────┴──────────────────┘
```

Ожидаемо пик продаж приходится на субботу и воскресенье. Более глубокую аналитику можно будет сделать перед обучением модели. Сейчас мы узнали достаточно для того, чтобы сформулировать задачу.

Мы можем обучить модель предсказывать полную выручку за сутки для любого магазина в заданный день. Директор не доволен: он хочет знать выручку отдельно для каждой категории товаров. Объясняем директору, что с нашими данными это невозможно, директору приходится согласиться на наш вариант.

При планировании региональные менеджеры будут использовать прогноз общей выручки и умножать его на среднюю долю продаж каждой категории товаров. Если модель предсказывает выручку 500 тысяч рублей в следующее воскресенье, а крупы в среднем составляют 10% общих продаж, значит нужно будет закупить круп на 50 тысяч рублей.

## Получить данные

В соревнованиях у нас есть `train.csv` и `test.csv`. Сейчас у нас есть только база данных.

Посмотрим на таблицу `sales` еще раз:

```sqlite
SELECT * FROM sales LIMIT 5;
```
```text {.no-copy}
┌─────────┬──────────┬────────────┬───────┬─────────────┬────────────┬──────────┬────────┐
│ sale_id │ store_id │    date    │ month │ day_of_week │ is_holiday │ is_promo │ amount │
├─────────┼──────────┼────────────┼───────┼─────────────┼────────────┼──────────┼────────┤
│ 0       │ 1        │ 2025-07-31 │ 7     │ 4           │ 0          │ 1        │ 315780 │
│ 1       │ 2        │ 2025-07-31 │ 7     │ 4           │ 0          │ 1        │ 363840 │
│ 2       │ 3        │ 2025-07-31 │ 7     │ 4           │ 0          │ 1        │ 498840 │
│ 3       │ 4        │ 2025-07-31 │ 7     │ 4           │ 0          │ 1        │ 839700 │
│ 4       │ 5        │ 2025-07-31 │ 7     │ 4           │ 0          │ 1        │ 289320 │
└─────────┴──────────┴────────────┴───────┴─────────────┴────────────┴──────────┴────────┘
```

В ней нет данных о магазинах, но мы можем попробовать обучить первую модель без них. Нам понадобятся только колонки с номером месяца, дня недели, информация о праздниках, промо-акциях и объем продаж для предсказания:

```sqlite
SELECT month, day_of_week, is_promo, is_holiday, amount FROM sales LIMIT 5;
```
```text {.no-copy}
┌───────┬─────────────┬──────────┬────────────┬────────┐
│ month │ day_of_week │ is_promo │ is_holiday │ amount │
├───────┼─────────────┼──────────┼────────────┼────────┤
│ 7     │ 4           │ 1        │ 0          │ 315780 │
│ 7     │ 4           │ 1        │ 0          │ 363840 │
│ 7     │ 4           │ 1        │ 0          │ 498840 │
│ 7     │ 4           │ 1        │ 0          │ 839700 │
│ 7     │ 4           │ 1        │ 0          │ 289320 │
└───────┴─────────────┴──────────┴────────────┴────────┘
```

Перейдем к Python проекту. Для работы с данными будем использовать Pandas, а в качестве модели возьмем CatBoost. Установим все зависимости:

```shell
uv add pandas catboost
```

Загрузим данные из базы данных и сохраним их в CSV файл, который потом можно будет прочитать. Для этого используем Pandas. Создаем модуль `load.py`, импортируем встроенную библиотеку `sqlite3` и `pandas`. Переписываем SQL запрос. Заберем все данные до начала 2025 года для обучения:

```python title="load.py"
import sqlite3
import pandas as pd

query = """
SELECT
    month,
    day_of_week,
    is_promo,
    is_holiday,
    amount
FROM sales
WHERE date < '2025-01-01';
"""
```

Подключаемся к базе данных с помощью контекстного менеджера `sqlite3.connect` и передаем ему имя файла с базой данных. Выполняем запрос с помощью функции `read_sql`. Выводим на экран первые пять строк таблицы и ее размерность для проверки и записываем ее в файл `train.csv`:

```python title="load.py" hl_lines="15-20"
import sqlite3
import pandas as pd

query = """
SELECT
    month,
    day_of_week,
    is_promo,
    is_holiday,
    amount
FROM sales
WHERE date < '2025-01-01';
"""

with sqlite3.connect("data.db") as connection:
    data = pd.read_sql(query, connection)

print(data.head())
print(data.shape)
data.to_csv("train.csv", index=False)
```
```text {.no-copy}
   month  day_of_week  is_promo  is_holiday  amount
0     12            2         0           0  156300
1     12            2         0           0  228240
2     12            2         0           0  609120
3     12            2         0           0  156240
4     12            2         0           0  313140
(619945, 5)
```

В выборке обучения будет 620 тысяч строк. Теперь сохраним тестовую выборку — для нее возьмем данные с начала 2025 года. Меняем знак "<" на ">=" и имя файла на `test.csv`:

```python title="load.py" hl_lines="12 18"
import sqlite3
import pandas as pd

query = """
SELECT
    month,
    day_of_week,
    is_promo,
    is_holiday,
    amount
FROM sales
WHERE date >= '2025-01-01';
"""

with sqlite3.connect("data.db") as connection:
    data = pd.read_sql(query, connection)

print(data.head())
print(data.shape)
data.to_csv("test.csv", index=False)
```
```text {.no-copy}
   month  day_of_week  is_promo  is_holiday  amount
0      7            4         1           0  315780
1      7            4         1           0  363840
2      7            4         1           0  498840
3      7            4         1           0  839700
4      7            4         1           0  289320
(188509, 5)
```

В тестовой выборке будет 180 тысяч строк.

Перейдем к обучению. Импортируем `pandas` для работы с данными и читаем таблицы `train.csv` и `test.csv`, которые мы только что сохранили. Убираем из таблицы с признаками колонку с объемом продаж — ее будет предсказывать модель. Повторяем все действия для выборки обучения и тестовой выборки:

```python title="train.py"
import pandas as pd

train_data = pd.read_csv("train.csv")
test_data = pd.read_csv("test.csv")

X_train = train_data.drop(columns=["amount"])
y_train = train_data["amount"]
X_test = test_data.drop(columns=["amount"])
y_test = test_data["amount"]
```

Импортируем модель `CatBoostRegressor` из библиотеки `catboost`. В качестве метрики используем средний процент отклонения из пакета `sklearn.metrics`. Инициализируем модель, вызываем метод `fit` и передаем ему данные выборки обучения. После обучения вычисляем средний процент отклонения модели на тестовой выборке и выводим его значение на экран:

```python title="train.py" hl_lines="2-3 13-17"
import pandas as pd
from catboost import CatBoostRegressor
from sklearn.metrics import mean_absolute_percentage_error

train_data = pd.read_csv("train.csv")
test_data = pd.read_csv("test.csv")

X_train = train_data.drop(columns=["amount"])
y_train = train_data["amount"]
X_test = test_data.drop(columns=["amount"])
y_test = test_data["amount"]

model = CatBoostRegressor()
model.fit(X_train, y_train)

score = mean_absolute_percentage_error(y_test, model.predict(X_test))
print(f"Ошибка на тестовой выборке: {100 * score:.1f}%")
```
```text {.no-copy
Ошибка на тестовой выборке: 27.0%
```
90+75+55+90+100

Получаем среднее отклонение на тестовой выборке в 27%. Например, если реальная выручка магазина за сутки составила 600 тысяч рублей, модель в среднем может предсказать выручку от 400 до 800 тысяч.

## Объединить таблицы

Как на продажи влияют общие факторы: время года, праздники, выходные и распродажи. Но при этом модель ничего не знает о крупных и 

Отклонение в 30% можно объяснить. Мы использовали всего 4 признака. Модель знает только общие сезонные закономерности — как в среднем продажи распределяются по месяцам в году и по дням недели, как на продажи влияют акции и праздники. Но мы не учитываем данные магазинов: тип магазина, ассортимент и насколько близко к нему есть магазины конкурентов.

Для того чтобы собрать такой набор данных, нужно объединить две таблицы в одну. Для этого SQL нужно дать понять, как соединить строки. Для этого нужны ID или ключи. Они уникальные для каждой строки и называются "PRIMARY KEY". В таблице `sales` ключ `sale_id`, а в таблице `stores` — `store_id`.

Кроме ID строки в таблице `sales` есть ID магазина `store_id` — его называют "FOREIGN KEY". Ключи `store_id` в таблице `sales` и `stores` должны совпасть, так мы будем знать что речь идет об одном и том же магазине.

После объединения мы можем обращаться к колонкам в обеих таблицах. Возьмем колонки `date` и `amount` из таблицы `sales` и колонку `store_type` из таблицы `stores`. Объединим их используя ключ `store_id`:

```sqlite
SELECT date, store_type, amount FROM sales JOIN stores USING(store_id) LIMIT 5;
```
```text {.no-copy}
┌────────────┬─────────────┬────────┐
│    date    │ store_type  │ amount │
├────────────┼─────────────┼────────┤
│ 2025-07-31 │ супермаркет │ 315780 │
│ 2025-07-31 │ стандарт    │ 363840 │
│ 2025-07-31 │ стандарт    │ 498840 │
│ 2025-07-31 │ супермаркет │ 839700 │
│ 2025-07-31 │ стандарт    │ 289320 │
└────────────┴─────────────┴────────┘
```

В результате мы получаем колонки из обеих таблиц.

В объединенной таблице можно найти больше интересных закономерностей. Например, какие продажи в среднем у магазинов каждого типа:

```sqlite
SELECT store_type, AVG(amount) FROM sales JOIN stores USING(store_id) GROUP BY store_type;
```
```text {.no-copy}
┌─────────────┬──────────────────┐
│ store_type  │   AVG(amount)    │
├─────────────┼──────────────────┤
│ мини        │ 406426.804514395 │
│ стандарт    │ 407167.354313378 │
│ супермаркет │ 410051.590890435 │
│ универсам   │ 512573.170656371 │
└─────────────┴──────────────────┘
```

Тут выделяются универсамы — их выручка больше в среднем на четверть.

Можно посмотреть выручку в разрезе ассортимента:

```sqlite
SELECT assortment, AVG(amount) FROM sales JOIN stores USING(store_id) GROUP BY assortment;
```
```text {.no-copy}
┌─────────────┬──────────────────┐
│ assortment  │   AVG(amount)    │
├─────────────┼──────────────────┤
│ базовый     │ 424229.478572588 │
│ расширенный │ 394016.517298669 │
│ широкий     │ 493714.423945297 │
└─────────────┴──────────────────┘
```

Тут интересно, что товары первой необходимости из базового ассортимента приносят большую выручку по сравнению с расширенным ассортиментом.

Вернемся к обучению. Обновим файлы `train.csv` и `test.csv`. Добавим к ним колонки из таблицы `stores`: тип магазина, ассортимент и расстояние до ближайшего магазина-конкурента. Чтобы получить доступ к этим колонкам добавляем команду `INNER JOIN` для объединения таблиц по ключу `store_id`:

```python title="load.py"
import sqlite3
import pandas as pd

query = """
SELECT
    month,
    day_of_week,
    is_promo,
    is_holiday,
    amount,
    store_type,
    assortment,
    competition_distance
FROM sales
JOIN stores USING(store_id)
WHERE date < '2025-01-01';
"""

with sqlite3.connect("data.db") as connection:
    data = pd.read_sql(query, connection)

print(data.head())
print(data.shape)
data.to_csv("train.csv", index=False)
```
```text
   month  day_of_week  is_promo  is_holiday  amount   store_type   assortment  competition_distance
0     12            2         0           0  156300  супермаркет  расширенный                  1270
1     12            2         0           0  228240     стандарт  расширенный                 14130
2     12            2         0           0  609120  супермаркет      базовый                   620
3     12            2         0           0  156240     стандарт  расширенный                   310
4     12            2         0           0  313140     стандарт      базовый                 24000
(619945, 8)
```

```python title="load.py"
import sqlite3
import pandas as pd

query = """
SELECT
    month,
    day_of_week,
    is_promo,
    is_holiday,
    amount,
    store_type,
    assortment,
    competition_distance
FROM sales
JOIN stores USING(store_id)
WHERE date >= '2025-01-01';
"""

with sqlite3.connect("data.db") as connection:
    data = pd.read_sql(query, connection)

print(data.head())
print(data.shape)
data.to_csv("test.csv", index=False)
```
```text
   month  day_of_week  is_promo  is_holiday  amount   store_type   assortment  competition_distance
0      7            4         1           0  315780  супермаркет  расширенный                  1270
1      7            4         1           0  363840     стандарт  расширенный                   570
2      7            4         1           0  498840     стандарт  расширенный                 14130
3      7            4         1           0  839700  супермаркет      базовый                   620
4      7            4         1           0  289320     стандарт  расширенный                 29910
(188509, 8)
```

Меняем условие и сохраняем тестовую выборку.

Обучим модель на новых данных. Теперь в них есть два категориальных признака: `store_type` и `assortment`. Передаем их конструктору `CatBoostRegressor` и перезапускаем обучение:

```python title="train.py" hl_lines="13"
import pandas as pd
from catboost import CatBoostRegressor
from sklearn.metrics import mean_absolute_percentage_error

train_data = pd.read_csv("train.csv")
test_data = pd.read_csv("test.csv")

X_train = train_data.drop(columns=["amount"])
y_train = train_data["amount"]
X_test = test_data.drop(columns=["amount"])
y_test = test_data["amount"]

model = CatBoostRegressor(cat_features=["store_type", "assortment"])
model.fit(X_train, y_train)

score = mean_absolute_percentage_error(y_test, model.predict(X_test))
print(f"Ошибка на тестовой выборке: {100 * score:.1f}%")
```
```text {.co-copy}
Ошибка на тестовой выборке: 18.4%
```

Ошибка снизилась на треть — с 27% до 18%. 

## Как оно в реальности

В этом примере у нас на руках оказалась копия базы данных. Мы перекладываем данные из одного файла в другой.

На самом деле будет база данных в облаке. Вам дадут ее адрес, логин и пароль. В зависимости от типа базы вы будете использовать не sqlite3 а другой клиент. Но ничего больше не изменится. Например, если это Postgres, установим `psycopg`, поменяем вызов соединения с базой:

```python title="load.py"
import pandas as pd
from sqlalchemy import create_engine

query = """
SELECT
    month,
    day_of_week,
    is_promo,
    is_holiday,
    amount,
    store_type,
    assortment,
    competition_distance
FROM sales
JOIN stores USING(store_id)
WHERE date < '2025-01-01';
"""

engine = create_engine("postgresql://ivanov:ivanov123@5.129.250.215:5432/supermarket")
data = pd.read_sql(query, engine)

data.to_csv("train.csv", index=False)
```

Я поднял базу в облаке и переложил в нее те же данные. Получаем тот же результат.

+ тут же можно переключиться обратно на sqlite:

```python
engine = create_engine("postgresql:///data.db")
```
